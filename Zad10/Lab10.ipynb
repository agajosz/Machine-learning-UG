{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python392jvsc74a57bd07812ea015bdcee6f23a998adcdd2ef97c151c0c241b7b7070987d9313e41299d",
   "display_name": "Python 3.9.2 64-bit ('3.9')"
  },
  "metadata": {
   "interpreter": {
    "hash": "7812ea015bdcee6f23a998adcdd2ef97c151c0c241b7b7070987d9313e41299d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "scaling_factor = 0.5\n",
    "frame = cv2.imread('mordka.jpg')\n",
    "frame = cv2.resize(frame, None, fx = scaling_factor, fy = scaling_factor, interpolation=cv2.INTER_AREA)\n",
    "face_rects = face_cascade.detectMultiScale(frame, scaleFactor=1.3, minNeighbors=5)\n",
    "\n",
    "for(x,y,w,h) in face_rects:\n",
    "    cv2.rectangle(frame, (x,y), (x+w, y+h), (255,0,0), 3)\n",
    "    \n",
    "cv2.imshow('mordka.jpg', frame)\n",
    "cv2.waitKey(0)\n",
    "print(f'Found {len(face_rects)} face(s)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "scaling_factor = 0.5\n",
    "frame = cv2.imread('mordki.jpg')\n",
    "#frame = cv2.resize(frame, None, fx = scaling_factor, fy = scaling_factor, interpolation=cv2.INTER_AREA)\n",
    "face_rects = face_cascade.detectMultiScale(frame, scaleFactor=1.3, minNeighbors=3)\n",
    "\n",
    "for(x,y,w,h) in face_rects:\n",
    "    cv2.rectangle(frame, (x,y), (x+w, y+h), (255,0,0), 2)\n",
    "    \n",
    "cv2.imshow('mordki.jpg', frame)\n",
    "cv2.waitKey(0)\n",
    "print(f'Found {len(face_rects)} face(s)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "nose_cascade = cv2.CascadeClassifier('haarcascade_mcs_nose.xml')\n",
    "smile_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_smile.xml')\n",
    "eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')\n",
    "\n",
    "image = cv2.imread('mordki.jpg')\n",
    "gray_filter = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "faces = face_cascade.detectMultiScale(gray_filter, scaleFactor=1.3, minNeighbors=3)\n",
    "\n",
    "for(x,y,w,h) in faces:\n",
    "    cv2.rectangle(image, (x,y), (x+w, y+h), (255,0,0), 2)\n",
    "    roi_gray = gray_filter[y:y+h, x:x+w]\n",
    "    roi_color = image[y:y+h, x:x+w]\n",
    "    smile = smile_cascade.detectMultiScale(roi_gray)\n",
    "    eye = eye_cascade.detectMultiScale(roi_gray)\n",
    "    nose = nose_cascade.detectMultiScale(roi_gray)\n",
    "    for(sx,sy,sw,sh) in smile:\n",
    "        cv2.rectangle(roi_color, (sx,sy), (sx+sw, sy+sh), (0,255,0), 1)\n",
    "    for(ex,ey,ew,eh) in eye:\n",
    "        cv2.rectangle(roi_color, (ex,ey), (ex+ew, ey+eh), (0,0,255), 1)\n",
    "    for(nx,ny,nw,nh) in nose:\n",
    "        cv2.rectangle(roi_color, (nx,ny), (nx+nw, ny+nh), (0,0,255), 1)\n",
    "\n",
    "cv2.imshow(\"mordki.jpg\", image)\n",
    "cv2.waitKey(0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaling_factor = 0.5\n",
    "hog = cv2.HOGDescriptor()\n",
    "hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())\n",
    "image = cv2.imread('ludki.jpg')\n",
    "image = cv2.resize(image, None, fx=scaling_factor, fy=scaling_factor, interpolation=cv2.INTER_AREA)\n",
    "\n",
    "people_rects = hog.detectMultiScale(image, winStride=(3,3), padding=(5,5), scale=1.06)\n",
    "\n",
    "for(x,y,w,h) in people_rects[0]:\n",
    "    cv2.rectangle(image, (x,y), (x+w, y+h), (0,255,0), 2)\n",
    "\n",
    "cv2.imshow('ludki.jpg', image)\n",
    "cv2.waitKey(0)\n",
    "print(f'Found {len(people_rects[0])} people!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-ef7185342225>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m320\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m180\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "hog = cv2.HOGDescriptor()\n",
    "hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "cv2.startWindowThread()\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    frame = cv2.resize(frame, (320,180))\n",
    "    \n",
    "    gray_filter = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n",
    "    boxes = face_cascade.detectMultiScale(gray_filter, 7, 4)\n",
    "    boxes = np.array([[x,y,x+w,y+h] for (x,y,w,h) in boxes])\n",
    "    \n",
    "    for(xa,ya,xb,yb) in boxes:\n",
    "        cv2.rectangle(frame, (xa,ya),(xb,yb), (0,255,0),1)\n",
    "        cv2.imshow('Camera', frame)\n",
    "        k = cv2.waitKey(33)\n",
    "        if k == -1:  # if no key was pressed, -1 is returned\n",
    "            continue\n",
    "        else:\n",
    "            break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'cv2' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-85f2a0f6f709>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mface_cascade\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCascadeClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhaarcascades\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'haarcascade_frontalface_default.xml'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartWindowThread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVideoCapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cv2' is not defined"
     ]
    }
   ],
   "source": [
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "cv2.startWindowThread()\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    frame = cv2.resize(frame, (800,560))\n",
    "    \n",
    "    gray_filter = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n",
    "    boxes = face_cascade.detectMultiScale(gray_filter, 7, 4)\n",
    "    boxes = np.array([[x,y,x+w,y+h] for (x,y,w,h) in boxes])\n",
    "    \n",
    "    for(xa,ya,xb,yb) in boxes:\n",
    "        cv2.rectangle(frame, (xa,ya),(xb,yb), (0,255,0),1)\n",
    "        cv2.imshow(\"Video\", frame)\n",
    "        k = cv2.waitKey(33)\n",
    "        if k == -1:  # if no key was pressed, -1 is returned\n",
    "            continue\n",
    "        else:\n",
    "            break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hog = cv2.HOGDescriptor()\n",
    "hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())\n",
    "cv2.startWindowThread()\n",
    "cap = cv2.VideoCapture('video.mp4')\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    frame = cv2.resize(frame, (320,180))\n",
    "    gray_filter = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n",
    "    boxes, weights = hog.detectMultiScale(frame, winStride=(3,3), padding=(3,3))\n",
    "    boxes = np.array([[x,y,x+w,y+h] for (x,y,w,h) in boxes])\n",
    "    \n",
    "    for(xa,ya,xb,yb) in boxes:\n",
    "        cv2.rectangle(frame, (xa,ya),(xb,yb), (0,255,0),1)\n",
    "        cv2.imshow(\"Video\", frame)\n",
    "        k = cv2.waitKey(33)\n",
    "        if k == -1:  # if no key was pressed, -1 is returned\n",
    "            continue\n",
    "        else:\n",
    "            break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}